---
output: pdf_document
title: Missing data and inclusion of (co)variances of exogeneous variables
---

# Dealing with missing data 

We will analyse the Holzinger Swineford data included in the **`lavaan`** package.

```{r, warning=FALSE, message=FALSE}
library("lavaan")
summary(HolzingerSwineford1939)
nrow(HolzingerSwineford1939)
```
See `?HolzingerSwineford` for more info.

We will fit a three-factor CFA model to the $x$ variables in the dataset:

```{r}
HS.model <- '
  visual  =~ x1 + x2 + x3
  textual =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9
'
```


## Benchmark: Complete data

```{r}
CD_fit <- cfa(HS.model, data = HolzingerSwineford1939, meanstructure = TRUE)
(CD_summ <- summary(CD_fit, standardized = TRUE))
fit.inds <- c("chisq", "df", "pvalue", "cfi", "rmsea", "srmr", "aic", "bic")
(CD_fitm <- fitmeasures(CD_fit, fit.inds))
```

## Create missing values

We introduce some missing values. The values will be missing completely at random, with a probability of .2 for any value being missing:

```{r}
HSMiss <- HolzingerSwineford1939[,paste("x", 1:9, sep="")]
set.seed(42)
randomMiss <- rbinom(prod(dim(HSMiss)), 1, 0.20)
randomMiss <- matrix(as.logical(randomMiss), nrow=nrow(HSMiss))
HSMiss[randomMiss] <- NA
head(HSMiss)
```

Some values are now missing. 

## Listwise deletion approach

By default, functions `cfa()`, `growth()`, `lavaan()` and `sem()` will remove every observation with missing values, which drastically decreases sample size:

```{r}
LD_fit <- cfa(HS.model, data = HSMiss, meanstructure = TRUE)
## lavInspect(LD_fit, "cov.lv") ## suppressed, because same output given below
(LD_summ <- summary(LD_fit, standardized = TRUE))
(LD_fitm <- fitmeasures(LD_fit, fit.inds))
```

Using listwise deletion, we have only 50 observations left. We also get warnings about the (co)variance matrix of the latent variables being problematic. Furthermore, the estimated loadings, intercepts and variances seem more variable than before.


## Multiple imputation approach

We now impute the data using package **`mice`**. We use generate five imputed datasets and use the predictive mean matching method, which is the current state of the art in missing data imputation (although many would suggest using a higher value for $m$; increasing $m$ will never hurt quality of results, but it will make computations longer, so for the current simple example I opt for computation speed):

```{r, warning=FALSE, message=FALSE}
library("mice")
m <- 5
set.seed(42)
imp_data <- mice(HSMiss, m = m, method = "pmm")
```

We extract the imputed datasets using function `complete()` and save them in a list:

```{r}
data_list <- list()
for (i in 1:m) data_list[[i]] <- complete(imp_data, action = i)
lapply(data_list, head) ## show first few rows of every imputed dataset
```

We see that the missing values have been imputed with different values in every dataset.

Now we use the `cfa.mi()` function to fit a CFA model on the imputed data:

```{r, warning=FALSE, message=FALSE}
library("lavaan.mi")
```

```{r}
MI_fit <- cfa.mi(HS.model, data_list, meanstructure = TRUE)
(MI_summ <- summary(MI_fit, standardized = TRUE))
```

We see that fitting a SEM model on imputed data is quite straightforward: we use function `cfa.mi()` instead of `cfa()`. Using function `summary()`, we obtain the pooled result. The output is very similar to what were used to with a single dataset. One of the differences is that with imputed data, we get $t$ instead of $z$ statistics for every parameter estimate. 

```{r}
(MI_fitm <- fitmeasures(MI_fit))
```


#### Full information Maximum Likelihood (FIML)

```{r}
FIML_fit <- cfa(HS.model, data = HSMiss, missing = "ml")
(FIML_summ <- summary(FIML_fit, standardized = TRUE))
(FIML_fitm <- fitmeasures(LD_fit, fit.inds))
```


## Comparison of methods

We compare parameter estimates and standard errors between the complete dataset, listwise deletion, multiple imputation and FIML:

```{r}
comp_data <- data.frame(
  method = rep(c("CD", "LD", "MI", "FIML"), each = nrow(LD_summ$pe)),
  rbind(
    CD_summ$pe[c(1:3, 5:6)], ## parameter estimates from listw. deletion model
    LD_summ$pe[c(1:3, 5:6)],
    MI_summ$pe[c(1:3, 5:6)],
    FIML_summ$pe[c(1:3, 5:6)]
  )
)
comp_data <- comp_data[comp_data$se > 0, ] ## omit fixed parameters
head(comp_data)
```

Those are a lot of numbers to compare, let's plot some comparisons:

```{r}
par(mfrow = c(2, 3))
## Plot the parameter estimates
plot(comp_data$est[comp_data$method == "CD"], 
     comp_data$est[comp_data$method == "LD"], 
     xlim = c(0, 7), ylim = c(0, 7),
     cex.axis = .7, cex.lab= .7, cex.main = .7,
     main = "parameter estimates LD vs CD",
     xlab = "parameter estimates complete data",
     ylab = "parameter estimates listwise deletion")
abline(0, 1)
plot(comp_data$est[comp_data$method == "CD"], 
     comp_data$est[comp_data$method == "MI"], 
     xlim = c(0, 7), ylim = c(0, 7), 
     cex.axis = .7, cex.lab= .7, cex.main = .7,
     main = "parameter estimates MI vs CD",
     ylab = "parameter estimates multiple imputation",
     xlab = "parameter estimates complete data")
abline(0, 1)
plot(comp_data$est[comp_data$method == "CD"], 
     comp_data$est[comp_data$method == "FIML"], 
     xlim = c(0, 7), ylim = c(0, 7), 
     cex.axis = .7, cex.lab= .7, cex.main = .7,
     main = "parameter estimates FIML vs CD",
     ylab = "parameter estimates full information ML",
     xlab = "parameter estimates complete data")
abline(0, 1)

## plot the standard errors
plot(comp_data$se[comp_data$method == "CD"], 
     comp_data$se[comp_data$method == "LD"], 
     xlim = c(0, 0.5), ylim = c(0, 0.5),
     cex.axis = .7, cex.lab= .7, cex.main = .7,
     main = "standard errors LD vs CD",
     xlab = "SEs complete data",
     ylab = "SEs listwise deletion")
abline(0, 1)
plot(comp_data$se[comp_data$method == "CD"], 
     comp_data$se[comp_data$method == "MI"], 
     xlim = c(0, 0.5), ylim = c(0, 0.5), 
     cex.axis = .7, cex.lab= .7, cex.main = .7,
     main = "standard errors MI vs CD",
     ylab = "SEs multiple imputation",
     xlab = "SEs complete data")
abline(0, 1)
plot(comp_data$se[comp_data$method == "CD"], 
     comp_data$se[comp_data$method == "FIML"], 
     xlim = c(0, 0.5), ylim = c(0, 0.5), 
     cex.axis = .7, cex.lab= .7, cex.main = .7,
     main = "standard errors FIML vs CD",
     ylab = "SEs full information ML",
     xlab = "SEs complete data")
abline(0, 1)
```

(Note, two very large outlying standard errors for listwise deletion have been omitted from the plots, so we can focus on the patterns shown by the less extreme cases, so the standard errors for listwise deletion are even worse than what we see here.)

Top panels: Parameter estimates for listwise deletion deviate considerably from those obtained with the complete data. This is largely corrected by using either multiple imputation or full information ML.

Bottom panels: Listwise deletion yields much larger standard errors than we would obtain with the complete data. The standard errors obtained with multiple imputation and full information ML are (much) closer to those obtained with the complete data. They are still a bit larger, which they should be, because there is of course missing data, which should result in lower prediction of the estimates.


\newpage

# Parameters relating to exogenous variables

In many SEM analyses, parameters relating to exogenous variables will often not be provided. Often, exogenous variables will be considered fixed. As a result, their (co)variances are fixed to their sample (co)variances, instead of being estimated as parameters in the model. For the model fit ($\chi^2$ and $df$), this does not make a difference. But sometimes you may want to inspect the variation or associations between the exogonous variables.

```{r}
HS_data <- HolzingerSwineford1939
HS_data$age <- with(HS_data, ageyr + agemo/12)
HS_data$sex <- HS_data$sex - 1 # to make it 0-1 coded
HS.model2 <- '
  visual  =~ x1 + x2 + x3
  textual =~ x4 + x5 + x6
  visual + textual ~ sex + age
'
HS_mod1 <- cfa(HS.model2, data = HS_data, estimator = "MLR")
summary(HS_mod1, standardized = TRUE)
```

We see that the (co)variances of the exogenous variables (`sex` and `age`) are not estimated in the model. As a results, we cannot inspect their association. To include them in the model as model parameters, we have to additionally specify `fixed.x = FALSE` in the call to `cfa()`: 

```{r}
HS_mod2 <- cfa(HS.model2, data = HS_data, estimator = "MLR", fixed.x = FALSE)
summary(HS_mod2, standardized = TRUE)
```